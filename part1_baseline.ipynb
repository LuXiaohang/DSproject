{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sushi' 'greek_salad' 'mussels' 'paella' 'omelette' 'frozen_yogurt'\n",
      " 'beef_tartare' 'caesar_salad' 'bibimbap' 'filet_mignon']\n"
     ]
    }
   ],
   "source": [
    "class_to_ix = {}\n",
    "ix_to_class = {}\n",
    "with open('food101/meta/classes.txt', 'r') as txt:\n",
    "    classes = [l.strip() for l in txt.readlines()]\n",
    "    class_to_ix = dict(zip(classes, range(len(classes))))\n",
    "    ix_to_class = dict(zip(range(len(classes)), classes))\n",
    "    class_to_ix = {v: k for k, v in ix_to_class.items()}\n",
    "keys = []\n",
    "for key,value in class_to_ix.items():\n",
    "    keys.append(key)\n",
    "print(np.random.choice(keys, size=10,replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pretrainedmodels\n",
    "import pretrainedmodels.utils\n",
    "plt.ion() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=200,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best test Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model = pretrainedmodels.__dict__[\"inceptionresnetv2\"](num_classes=1000,pretrained=\"imagenet\")\n",
    "features_size = model.last_linear.in_features\n",
    "model.last_linear = nn.Linear(features_size,10)\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 2.2415 Acc: 0.2193\n",
      "test Loss: 1.9244 Acc: 0.3648\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 2.0477 Acc: 0.2951\n",
      "test Loss: 1.8603 Acc: 0.3728\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 1.9645 Acc: 0.3340\n",
      "test Loss: 1.9124 Acc: 0.4176\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 1.8766 Acc: 0.3545\n",
      "test Loss: 1.5127 Acc: 0.5236\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 1.8365 Acc: 0.3835\n",
      "test Loss: 1.5558 Acc: 0.5068\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 1.7715 Acc: 0.4019\n",
      "test Loss: 1.4355 Acc: 0.5360\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 1.6953 Acc: 0.4333\n",
      "test Loss: 1.3561 Acc: 0.5600\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 1.4775 Acc: 0.5109\n",
      "test Loss: 1.0911 Acc: 0.6460\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 1.4628 Acc: 0.5195\n",
      "test Loss: 1.0903 Acc: 0.6420\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 1.4151 Acc: 0.5352\n",
      "test Loss: 1.0412 Acc: 0.6560\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 1.4110 Acc: 0.5356\n",
      "test Loss: 1.0556 Acc: 0.6520\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 1.3884 Acc: 0.5483\n",
      "test Loss: 1.0362 Acc: 0.6680\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 1.3854 Acc: 0.5447\n",
      "test Loss: 1.0375 Acc: 0.6732\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 1.3680 Acc: 0.5500\n",
      "test Loss: 1.0118 Acc: 0.6772\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 1.3360 Acc: 0.5577\n",
      "test Loss: 0.9651 Acc: 0.6880\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 1.3215 Acc: 0.5680\n",
      "test Loss: 0.9988 Acc: 0.6692\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 1.3387 Acc: 0.5587\n",
      "test Loss: 0.9735 Acc: 0.6844\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18()\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/33\n",
      "----------\n",
      "train Loss: 1.3005 Acc: 0.5697\n",
      "test Loss: 0.9390 Acc: 0.6980\n",
      "\n",
      "Epoch 1/33\n",
      "----------\n",
      "train Loss: 1.3268 Acc: 0.5675\n",
      "test Loss: 0.9477 Acc: 0.6936\n",
      "\n",
      "Epoch 2/33\n",
      "----------\n",
      "train Loss: 1.3024 Acc: 0.5705\n",
      "test Loss: 0.9782 Acc: 0.6836\n",
      "\n",
      "Epoch 3/33\n",
      "----------\n",
      "train Loss: 1.2996 Acc: 0.5724\n",
      "test Loss: 0.9526 Acc: 0.6928\n",
      "\n",
      "Epoch 4/33\n",
      "----------\n",
      "train Loss: 1.2986 Acc: 0.5780\n",
      "test Loss: 0.9413 Acc: 0.6912\n",
      "\n",
      "Epoch 5/33\n",
      "----------\n",
      "train Loss: 1.3115 Acc: 0.5735\n",
      "test Loss: 0.9517 Acc: 0.6896\n",
      "\n",
      "Epoch 6/33\n",
      "----------\n",
      "train Loss: 1.3010 Acc: 0.5735\n",
      "test Loss: 0.9634 Acc: 0.6920\n",
      "\n",
      "Epoch 7/33\n",
      "----------\n",
      "train Loss: 1.3013 Acc: 0.5727\n",
      "test Loss: 0.9578 Acc: 0.6864\n",
      "\n",
      "Epoch 8/33\n",
      "----------\n",
      "train Loss: 1.3169 Acc: 0.5719\n",
      "test Loss: 0.9501 Acc: 0.6872\n",
      "\n",
      "Epoch 9/33\n",
      "----------\n",
      "train Loss: 1.3112 Acc: 0.5721\n",
      "test Loss: 0.9480 Acc: 0.6988\n",
      "\n",
      "Epoch 10/33\n",
      "----------\n",
      "train Loss: 1.2919 Acc: 0.5839\n",
      "test Loss: 0.9779 Acc: 0.6920\n",
      "\n",
      "Epoch 11/33\n",
      "----------\n",
      "train Loss: 1.3135 Acc: 0.5737\n",
      "test Loss: 0.9360 Acc: 0.6936\n",
      "\n",
      "Epoch 12/33\n",
      "----------\n",
      "train Loss: 1.2976 Acc: 0.5749\n",
      "test Loss: 0.9620 Acc: 0.6912\n",
      "\n",
      "Epoch 13/33\n",
      "----------\n",
      "train Loss: 1.3145 Acc: 0.5653\n",
      "test Loss: 0.9607 Acc: 0.6864\n",
      "\n",
      "Epoch 14/33\n",
      "----------\n",
      "train Loss: 1.3221 Acc: 0.5667\n",
      "test Loss: 0.9643 Acc: 0.6788\n",
      "\n",
      "Epoch 15/33\n",
      "----------\n",
      "train Loss: 1.3225 Acc: 0.5619\n",
      "test Loss: 0.9765 Acc: 0.6824\n",
      "\n",
      "Epoch 16/33\n",
      "----------\n",
      "train Loss: 1.2977 Acc: 0.5804\n",
      "test Loss: 0.9515 Acc: 0.6864\n",
      "\n",
      "Epoch 17/33\n",
      "----------\n",
      "train Loss: 1.3051 Acc: 0.5728\n",
      "test Loss: 0.9722 Acc: 0.6788\n",
      "\n",
      "Epoch 18/33\n",
      "----------\n",
      "train Loss: 1.3179 Acc: 0.5652\n",
      "test Loss: 0.9720 Acc: 0.6864\n",
      "\n",
      "Epoch 19/33\n",
      "----------\n",
      "train Loss: 1.3074 Acc: 0.5688\n",
      "test Loss: 0.9757 Acc: 0.6896\n",
      "\n",
      "Epoch 20/33\n",
      "----------\n",
      "train Loss: 1.3228 Acc: 0.5680\n",
      "test Loss: 0.9523 Acc: 0.6964\n",
      "\n",
      "Epoch 21/33\n",
      "----------\n",
      "train Loss: 1.3090 Acc: 0.5709\n",
      "test Loss: 0.9813 Acc: 0.6896\n",
      "\n",
      "Epoch 22/33\n",
      "----------\n",
      "train Loss: 1.3161 Acc: 0.5716\n",
      "test Loss: 0.9391 Acc: 0.6988\n",
      "\n",
      "Epoch 23/33\n",
      "----------\n",
      "train Loss: 1.3087 Acc: 0.5736\n",
      "test Loss: 0.9912 Acc: 0.6828\n",
      "\n",
      "Epoch 24/33\n",
      "----------\n",
      "train Loss: 1.3027 Acc: 0.5753\n",
      "test Loss: 0.9344 Acc: 0.6932\n",
      "\n",
      "Epoch 25/33\n",
      "----------\n",
      "train Loss: 1.3282 Acc: 0.5653\n",
      "test Loss: 0.9731 Acc: 0.6852\n",
      "\n",
      "Epoch 26/33\n",
      "----------\n",
      "train Loss: 1.3276 Acc: 0.5699\n",
      "test Loss: 0.9729 Acc: 0.6868\n",
      "\n",
      "Epoch 27/33\n",
      "----------\n",
      "train Loss: 1.3096 Acc: 0.5712\n",
      "test Loss: 0.9325 Acc: 0.6944\n",
      "\n",
      "Epoch 28/33\n",
      "----------\n",
      "train Loss: 1.3225 Acc: 0.5655\n",
      "test Loss: 1.0112 Acc: 0.6860\n",
      "\n",
      "Epoch 29/33\n",
      "----------\n",
      "train Loss: 1.3210 Acc: 0.5660\n",
      "test Loss: 0.9411 Acc: 0.6956\n",
      "\n",
      "Epoch 30/33\n",
      "----------\n",
      "train Loss: 1.3118 Acc: 0.5696\n",
      "test Loss: 0.9475 Acc: 0.6860\n",
      "\n",
      "Epoch 31/33\n",
      "----------\n",
      "train Loss: 1.3189 Acc: 0.5659\n",
      "test Loss: 0.9516 Acc: 0.6900\n",
      "\n",
      "Epoch 32/33\n",
      "----------\n",
      "train Loss: 1.3169 Acc: 0.5688\n",
      "test Loss: 0.9731 Acc: 0.6924\n",
      "\n",
      "Epoch 33/33\n",
      "----------\n",
      "train Loss: 1.3130 Acc: 0.5751\n",
      "test Loss: 0.9570 Acc: 0.6884\n",
      "\n",
      "Training complete in 67m 17s\n",
      "Best test Acc: 0.698800\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
